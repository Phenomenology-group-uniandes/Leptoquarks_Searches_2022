{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25af2772-e499-4c59-98dc-a2bf48c6bea2",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin Peñuela Parra}$$\n",
    "$$\\textrm{Universidad de los Andes}$$\n",
    "$$\\textrm{Grupo de Física de Altas Energías: Fenomenología de Partículas}$$\n",
    "\n",
    "$\\textbf{Preliminares}$ \n",
    "\n",
    "Las librerías que se usan aquí son las siguientes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d32489e-1682-40f5-81c8-468de60fabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740ce45-a100-43f2-be42-36494879734e",
   "metadata": {},
   "source": [
    "Definamos las rutas que necesitamos para leer los archivos cutflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483a0606-f5de-405f-bae6-f917d47e7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_significances = os.path.dirname(os.path.realpath('Sheets_wo_RHC_JP.ipynb'))\n",
    "Path_Leptoquarks_searches = os.path.dirname(Path_significances)\n",
    "Path_Selected_Events = f'{Path_Leptoquarks_searches}/03_delphes_preselection/Selected_Events' #Carpeta donde están los csv preseleccionados\n",
    "Path_Tablas_XS = f'{Path_Leptoquarks_searches}/02_parton_analysis/XS_Matrix'\n",
    "Path_Composition_Charts = f'{Path_Leptoquarks_searches}/03_delphes_preselection/Composition_Charts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2147bb-f207-4a04-b568-47d27590fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['hadronic', 'semileptonic']\n",
    "processes = ['b_b_tau_tau', 'b_tau_tau']\n",
    "signals = ['LQ_LQ','Tau_LQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d3f02-7285-4e48-93a4-be4021c2589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = ['Data_5K_13_TeV']\n",
    "betards = {'Betard33_minus1': '', 'Betard33_0': '_wo_RHC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a49ca7-b780-4554-a1b2-b852f9a047d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eficiencia(process, channel, signal):\n",
    "    \n",
    "    path_csv = f'{Path_Selected_Events}/Cutflow_{process}_{channel}.csv'\n",
    "    cutflow = pd.read_csv(path_csv)\n",
    "    \n",
    "    return cutflow[signal][cutflow.shape[0]-2] #Así se extrae el valor de la penultima fila, esa es la eficiencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01acc2bb-939c-4787-b7ff-47e76400c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compositions = {}\n",
    "for betard in betards:\n",
    "    betard_name = betard.replace('33', '')\n",
    "    Compositions[betard_name] = {}\n",
    "    \n",
    "    for process in processes:\n",
    "        for channel in channels:\n",
    "            ruta = f'{process}_{channel}'\n",
    "            Compositions[betard_name][ruta] = pd.read_excel(f'{Path_Composition_Charts}/{betard}/{ruta}.xlsx', index_col = 0)\n",
    "            Compositions[betard_name][ruta].columns = [float(colum) for colum in Compositions[betard_name][ruta].columns]\n",
    "            Compositions[betard_name][ruta].index = [float(fila) for fila in Compositions[betard_name][ruta].index]\n",
    "        #Compositions[ruta].sort_index(level=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbb875-9305-466a-a84d-d21de461a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c491def-6733-44e9-8ff1-41759363cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tablas_XS = {}\n",
    "for betard in betards:\n",
    "    betard_name = betard.replace('33', '')\n",
    "    Tablas_XS[betard_name] = {}\n",
    "    for data in datas:\n",
    "        for signal in signals:\n",
    "            ruta = signal.replace('LQ_LQ','dLQ').replace('Tau_LQ', 'sLQ')\n",
    "            Tablas_XS[betard_name][ruta] = pd.read_excel(f'{Path_Tablas_XS}/{betard}/{data}_{signal}.xlsx', index_col = 0)\n",
    "            Tablas_XS[betard_name][ruta].columns = [float(colum) for colum in Tablas_XS[betard_name][ruta].columns]\n",
    "            Tablas_XS[betard_name][ruta].index = [float(fila) for fila in Tablas_XS[betard_name][ruta].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5136e-343a-4447-9995-e1a94b3e7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tablas_XS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83a8b2-15a7-44e7-8393-b7fa38aae887",
   "metadata": {},
   "outputs": [],
   "source": [
    "significances_files = ['all_combined', 'dLQ_combined', 'dLQ_hadronic', 'dLQ_semileptonic', 'sLQ_combined', 'sLQ_hadronic', 'sLQ_semileptonic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b9060a-b4dd-4fc7-9f06-48a81d152ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Significances = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57c471-2657-4213-b1bb-e3c36e96535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Significances['Betard_minus1'] = {}\n",
    "\n",
    "for file in significances_files:\n",
    "    \n",
    "    ruta = f'{Path_significances}/Excel_Files/Betard_minus1/{file}'\n",
    "    Significances['Betard_minus1'][file] = pd.read_excel(f'{ruta}.xlsx', index_col = 0)\n",
    "    Significances['Betard_minus1'][file].columns = [float(colum) for colum in Significances['Betard_minus1'][file].columns]\n",
    "    Significances['Betard_minus1'][file].index = [float(fila) for fila in Significances['Betard_minus1'][file].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c81857-06c1-4aab-9997-7a8b8db113e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Significances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae942bb8-3524-4afc-9675-bc3065936ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Masses = ['1000', '1250', '1500', '1750', '2000', '2250', '2500']\n",
    "g_Us = ['0.25', '0.5', '1', '1.5', '2.0', '2.5', '3.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f0720-8915-46cf-94db-3ed5ff3c85ac",
   "metadata": {},
   "source": [
    "Ahora usemos esto para construir las tablas de significancia con betard0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9411ece-09d9-4e35-8ada-3acd2cef0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Significances['Betard_0'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef4014-c466-4325-96ff-ea6befe94b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sLQ'\n",
    "channel = 'hadronic'\n",
    "process = 'b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0'][f'{file_name}'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1'][f'{file_name}'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC = Compositions['Betard_0'][f'{process}_{channel}'][M][g_U]\n",
    "        Composition_w_RHC = Compositions['Betard_minus1'][f'{process}_{channel}'][M][g_U]\n",
    "        \n",
    "        factor = np.sqrt((Eficiencia_M_wo_RHC/Eficiencia_M_w_RHC)*(XS_wo_RHC/XS_w_RHC)*(Composition_w_RHC/Composition_wo_RHC))        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3cd976-2d87-4f29-9c0b-82726d8e1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sLQ'\n",
    "channel = 'semileptonic'\n",
    "process = 'b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0'][f'{file_name}'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1'][f'{file_name}'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC = Compositions['Betard_0'][f'{process}_{channel}'][M][g_U]\n",
    "        Composition_w_RHC = Compositions['Betard_minus1'][f'{process}_{channel}'][M][g_U]\n",
    "        \n",
    "        factor = np.sqrt((Eficiencia_M_wo_RHC/Eficiencia_M_w_RHC)*(XS_wo_RHC/XS_w_RHC)*(Composition_w_RHC/Composition_wo_RHC))        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366fc18-f728-47f0-9f0b-4f55ee2de774",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dLQ'\n",
    "channel = 'hadronic'\n",
    "process = 'b_b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0']['sLQ'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1']['sLQ'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC = Compositions['Betard_0'][f'{process}_{channel}'][M][g_U]\n",
    "        Composition_w_RHC = Compositions['Betard_minus1'][f'{process}_{channel}'][M][g_U]\n",
    "        \n",
    "        factor = np.sqrt((Eficiencia_M_wo_RHC/Eficiencia_M_w_RHC)*(XS_wo_RHC/XS_w_RHC)*(Composition_w_RHC/Composition_wo_RHC))        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989a765-f2e6-4165-addd-7cd75ab9048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dLQ'\n",
    "channel = 'semileptonic'\n",
    "process = 'b_b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0']['sLQ'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1']['sLQ'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC = Compositions['Betard_0'][f'{process}_{channel}'][M][g_U]\n",
    "        Composition_w_RHC = Compositions['Betard_minus1'][f'{process}_{channel}'][M][g_U]\n",
    "        \n",
    "        factor = np.sqrt((Eficiencia_M_wo_RHC/Eficiencia_M_w_RHC)*(XS_wo_RHC/XS_w_RHC)*(Composition_w_RHC/Composition_wo_RHC))        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21a34f4-cf35-4f5c-addd-d29428d9211a",
   "metadata": {},
   "source": [
    "Solo falta las Combinadas de cada una y All Combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead6e15-a8d5-4ddc-9530-b5109cfc4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sLQ'\n",
    "channel = 'combined'\n",
    "\n",
    "channel_1 = 'hadronic'\n",
    "channel_2 = 'semileptonic'\n",
    "\n",
    "process = 'b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC_1 = Eficiencia(process, channel_1, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_1 = Eficiencia(process, channel_1, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        Eficiencia_M_wo_RHC_2 = Eficiencia(process, channel_2, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_2 = Eficiencia(process, channel_2, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        Composition_wo_RHC_1 = Compositions['Betard_0'][f'{process}_{channel_1}'][M][g_U]\n",
    "        Composition_w_RHC_1 = Compositions['Betard_minus1'][f'{process}_{channel_1}'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC_2 = Compositions['Betard_0'][f'{process}_{channel_2}'][M][g_U]\n",
    "        Composition_w_RHC_2 = Compositions['Betard_minus1'][f'{process}_{channel_2}'][M][g_U]\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0'][f'{file_name}'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1'][f'{file_name}'][M][g_U]\n",
    "        \n",
    "        numerador = (Eficiencia_M_wo_RHC_1/Composition_wo_RHC_1 + Eficiencia_M_wo_RHC_2/Composition_wo_RHC_2)*XS_wo_RHC\n",
    "        denominador = (Eficiencia_M_w_RHC_1/Composition_w_RHC_1 + Eficiencia_M_w_RHC_2/Composition_w_RHC_2)*XS_w_RHC\n",
    "        \n",
    "        factor = np.sqrt(numerador/denominador)        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809abc5a-b358-4a59-acb2-870d76075c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dLQ'\n",
    "channel = 'combined'\n",
    "\n",
    "channel_1 = 'hadronic'\n",
    "channel_2 = 'semileptonic'\n",
    "\n",
    "process = 'b_b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC_1 = Eficiencia(process, channel_1, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_1 = Eficiencia(process, channel_1, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        Eficiencia_M_wo_RHC_2 = Eficiencia(process, channel_2, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_2 = Eficiencia(process, channel_2, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        Composition_wo_RHC_1 = Compositions['Betard_0'][f'{process}_{channel_1}'][M][g_U]\n",
    "        Composition_w_RHC_1 = Compositions['Betard_minus1'][f'{process}_{channel_1}'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC_2 = Compositions['Betard_0'][f'{process}_{channel_2}'][M][g_U]\n",
    "        Composition_w_RHC_2 = Compositions['Betard_minus1'][f'{process}_{channel_2}'][M][g_U]\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0']['sLQ'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1']['sLQ'][M][g_U]\n",
    "        \n",
    "        numerador = (Eficiencia_M_wo_RHC_1/Composition_wo_RHC_1 + Eficiencia_M_wo_RHC_2/Composition_wo_RHC_2)*XS_wo_RHC\n",
    "        denominador = (Eficiencia_M_w_RHC_1/Composition_w_RHC_1 + Eficiencia_M_w_RHC_2/Composition_w_RHC_2)*XS_w_RHC\n",
    "        \n",
    "        factor = np.sqrt(numerador/denominador)        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea586d-950f-47a5-9233-0e97b377951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'all'\n",
    "channel = 'combined'\n",
    "\n",
    "channel_1 = 'hadronic'\n",
    "channel_2 = 'semileptonic'\n",
    "\n",
    "process_1 = 'b_tau_tau' #sLQ\n",
    "process_2 = 'b_b_tau_tau' #dLQ\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "        \n",
    "        #sLQ_hadronic\n",
    "        Eficiencia_M_wo_RHC_1 = Eficiencia(process_1, channel_1, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_1 = Eficiencia(process_1, channel_1, f'Tau_LQ_{Masses[j]}')\n",
    "        Composition_wo_RHC_1 = Compositions['Betard_0'][f'{process_1}_{channel_1}'][M][g_U]\n",
    "        Composition_w_RHC_1 = Compositions['Betard_minus1'][f'{process_1}_{channel_1}'][M][g_U]\n",
    "        \n",
    "        #sLQ_semiletpnic\n",
    "        Eficiencia_M_wo_RHC_2 = Eficiencia(process_1, channel_2, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_2 = Eficiencia(process_1, channel_2, f'Tau_LQ_{Masses[j]}')\n",
    "        Composition_wo_RHC_2 = Compositions['Betard_0'][f'{process_1}_{channel_2}'][M][g_U]\n",
    "        Composition_w_RHC_2 = Compositions['Betard_minus1'][f'{process_1}_{channel_2}'][M][g_U]\n",
    "        \n",
    "        #dLQ_hadronic\n",
    "        Eficiencia_M_wo_RHC_3 = Eficiencia(process_2, channel_1, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_3 = Eficiencia(process_2, channel_1, f'Tau_LQ_{Masses[j]}')\n",
    "        Composition_wo_RHC_3 = Compositions['Betard_0'][f'{process_2}_{channel_1}'][M][g_U]\n",
    "        Composition_w_RHC_3 = Compositions['Betard_minus1'][f'{process_2}_{channel_1}'][M][g_U]\n",
    "        \n",
    "        #dLQ_semiletpnic\n",
    "        Eficiencia_M_wo_RHC_4 = Eficiencia(process_2, channel_2, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_4 = Eficiencia(process_2, channel_2, f'Tau_LQ_{Masses[j]}')\n",
    "        Composition_wo_RHC_4 = Compositions['Betard_0'][f'{process_2}_{channel_2}'][M][g_U]\n",
    "        Composition_w_RHC_4 = Compositions['Betard_minus1'][f'{process_2}_{channel_2}'][M][g_U]\n",
    "        \n",
    "        \n",
    "        XS_wo_RHC_sLQ = Tablas_XS['Betard_0']['sLQ'][M][g_U]\n",
    "        XS_w_RHC_sLQ = Tablas_XS['Betard_minus1']['sLQ'][M][g_U]    \n",
    "        \n",
    "        numerador = (Eficiencia_M_wo_RHC_1/Composition_wo_RHC_1 + Eficiencia_M_wo_RHC_2/Composition_wo_RHC_2)*XS_wo_RHC_sLQ\n",
    "        + (Eficiencia_M_wo_RHC_3/Composition_wo_RHC_3 + Eficiencia_M_wo_RHC_4/Composition_wo_RHC_4)*XS_wo_RHC_sLQ\n",
    "        \n",
    "        denominador = (Eficiencia_M_w_RHC_1/Composition_w_RHC_1 + Eficiencia_M_w_RHC_2/Composition_w_RHC_2)*XS_w_RHC_sLQ\n",
    "        + (Eficiencia_M_w_RHC_3/Composition_w_RHC_3 + Eficiencia_M_w_RHC_4/Composition_w_RHC_4)*XS_w_RHC_sLQ\n",
    "        \n",
    "        factor = np.sqrt(numerador/denominador)        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14bfed-faf9-4f03-bd97-e29b024d1968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
