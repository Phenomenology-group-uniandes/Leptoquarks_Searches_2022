{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25af2772-e499-4c59-98dc-a2bf48c6bea2",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin Peñuela Parra}$$\n",
    "$$\\textrm{Universidad de los Andes}$$\n",
    "$$\\textrm{Grupo de Física de Altas Energías: Fenomenología de Partículas}$$\n",
    "\n",
    "$\\textbf{Preliminares}$ \n",
    "\n",
    "Las librerías que se usan aquí son las siguientes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d32489e-1682-40f5-81c8-468de60fabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740ce45-a100-43f2-be42-36494879734e",
   "metadata": {},
   "source": [
    "Definamos las rutas que necesitamos para leer los archivos cutflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483a0606-f5de-405f-bae6-f917d47e7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_significances = os.path.dirname(os.path.realpath('Sheets_wo_RHC_JP.ipynb'))\n",
    "Path_Leptoquarks_searches = os.path.dirname(Path_significances)\n",
    "Path_Selected_Events = f'{Path_Leptoquarks_searches}/03_delphes_preselection/Selected_Events' #Carpeta donde están los csv preseleccionados\n",
    "Path_Tablas_XS = f'{Path_Leptoquarks_searches}/02_parton_analysis/XS_Matrix'\n",
    "Path_Composition_Charts = f'{Path_Leptoquarks_searches}/03_delphes_preselection/Composition_Charts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2147bb-f207-4a04-b568-47d27590fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['hadronic', 'semileptonic']\n",
    "processes = ['b_b_tau_tau', 'b_tau_tau']\n",
    "signals = ['LQ_LQ','Tau_LQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361d3f02-7285-4e48-93a4-be4021c2589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = ['Data_5K_13_TeV']\n",
    "betards = {'Betard33_minus1': '', 'Betard33_0': '_wo_RHC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a49ca7-b780-4554-a1b2-b852f9a047d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eficiencia(process, channel, signal):\n",
    "    \n",
    "    path_csv = f'{Path_Selected_Events}/Cutflow_{process}_{channel}.csv'\n",
    "    cutflow = pd.read_csv(path_csv)\n",
    "    \n",
    "    return cutflow[signal][cutflow.shape[0]-2] #Así se extrae el valor de la penultima fila, esa es la eficiencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01acc2bb-939c-4787-b7ff-47e76400c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compositions = {}\n",
    "for betard in betards:\n",
    "    betard_name = betard.replace('33', '')\n",
    "    Compositions[betard_name] = {}\n",
    "    \n",
    "    for process in processes:\n",
    "        for channel in channels:\n",
    "            ruta = f'{process}_{channel}'\n",
    "            Compositions[betard_name][ruta] = pd.read_excel(f'{Path_Composition_Charts}/{betard}/{ruta}.xlsx', index_col = 0)\n",
    "            Compositions[betard_name][ruta].columns = [float(colum) for colum in Compositions[betard_name][ruta].columns]\n",
    "            Compositions[betard_name][ruta].index = [float(fila) for fila in Compositions[betard_name][ruta].index]\n",
    "        #Compositions[ruta].sort_index(level=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7fbb875-9305-466a-a84d-d21de461a4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Betard_minus1': {'b_b_tau_tau_hadronic':         1000.0    1250.0    1500.0    1750.0    2000.0    2250.0    2500.0\n",
       "  0.25  0.004962  0.006775  0.009129  0.012933  0.018333  0.026633  0.038355\n",
       "  0.50  0.019560  0.026460  0.035668  0.050102  0.069993  0.097564  0.138023\n",
       "  1.00  0.073489  0.097669  0.129098  0.173559  0.229670  0.303961  0.391133\n",
       "  1.50  0.152260  0.196357  0.248824  0.319519  0.402253  0.494653  0.590207\n",
       "  2.00  0.238218  0.297772  0.367101  0.452130  0.539081  0.632442  0.717766\n",
       "  2.50  0.320170  0.392108  0.468856  0.557853  0.642154  0.725943  0.796069\n",
       "  3.00  0.390353  0.466905  0.546738  0.632061  0.713015  0.786017  0.846095,\n",
       "  'b_b_tau_tau_semileptonic':         1000.0    1250.0    1500.0    1750.0    2000.0    2250.0    2500.0\n",
       "  0.25  0.004830  0.006631  0.008958  0.012711  0.017790  0.026402  0.037244\n",
       "  0.50  0.019048  0.025910  0.035019  0.049273  0.068026  0.096782  0.134429\n",
       "  1.00  0.071669  0.095784  0.126971  0.171055  0.224298  0.302077  0.383884\n",
       "  1.50  0.148802  0.192975  0.245281  0.315713  0.394914  0.492423  0.582800\n",
       "  2.00  0.233346  0.293280  0.362687  0.447784  0.531465  0.630365  0.711538\n",
       "  2.50  0.314313  0.386978  0.464116  0.553518  0.635088  0.724164  0.791065\n",
       "  3.00  0.383938  0.461539  0.542014  0.627968  0.706709  0.784512  0.842075,\n",
       "  'b_tau_tau_hadronic':         1000.0    1250.0    1500.0    1750.0    2000.0    2250.0    2500.0\n",
       "  0.25  0.016269  0.021730  0.029819  0.041460  0.057530  0.082274  0.118908\n",
       "  0.50  0.062054  0.081315  0.109837  0.148299  0.197431  0.261572  0.351409\n",
       "  1.00  0.208255  0.260625  0.330885  0.409431  0.493547  0.588621  0.684905\n",
       "  1.50  0.373279  0.443111  0.524949  0.607856  0.687461  0.762309  0.829739\n",
       "  2.00  0.509083  0.579992  0.659283  0.731495  0.792655  0.849346  0.895890\n",
       "  2.50  0.609645  0.677479  0.746501  0.806394  0.854344  0.896684  0.929620\n",
       "  3.00  0.679829  0.740409  0.800955  0.850097  0.890361  0.923286  0.948984,\n",
       "  'b_tau_tau_semileptonic':         1000.0    1250.0    1500.0    1750.0    2000.0    2250.0    2500.0\n",
       "  0.25  0.017206  0.023278  0.032039  0.043558  0.062327  0.088341  0.126098\n",
       "  0.50  0.065453  0.086731  0.117295  0.154926  0.211277  0.276871  0.366806\n",
       "  1.00  0.217805  0.274417  0.347492  0.421948  0.514838  0.607316  0.699163\n",
       "  1.50  0.386700  0.460545  0.543387  0.620070  0.705465  0.776114  0.838984\n",
       "  2.00  0.523310  0.597037  0.675727  0.741496  0.806307  0.859030  0.901967\n",
       "  2.50  0.623115  0.692665  0.760267  0.814313  0.864628  0.903670  0.933873\n",
       "  3.00  0.692100  0.753709  0.812506  0.856546  0.898404  0.928616  0.952128},\n",
       " 'Betard_0': {'b_b_tau_tau_hadronic':         1000.0    1250.0    1500.0    1750.0    2000.0    2250.0    2500.0\n",
       "  0.25  0.003106  0.004142  0.005839  0.008013  0.011446  0.016953  0.024503\n",
       "  0.50  0.012232  0.016257  0.022916  0.031654  0.044186  0.064620  0.091266\n",
       "  1.00  0.047363  0.062376  0.086374  0.115505  0.155509  0.215944  0.285811\n",
       "  1.50  0.100508  0.129403  0.173800  0.225734  0.293543  0.381911  0.473997\n",
       "  2.00  0.164427  0.207164  0.271269  0.340109  0.421904  0.520975  0.612561\n",
       "  2.50  0.232700  0.288250  0.364165  0.442619  0.531364  0.629150  0.713135\n",
       "  3.00  0.296650  0.363331  0.446924  0.527512  0.613539  0.705387  0.778194,\n",
       "  'b_b_tau_tau_semileptonic':         1000.0    1250.0    1500.0    1750.0    2000.0    2250.0    2500.0\n",
       "  0.25  0.003020  0.004041  0.005652  0.008032  0.011415  0.016762  0.024526\n",
       "  0.50  0.011896  0.015867  0.022192  0.031726  0.044071  0.063927  0.091343\n",
       "  1.00  0.046105  0.060950  0.083819  0.115745  0.155150  0.213999  0.286002\n",
       "  1.50  0.097986  0.126653  0.169137  0.226146  0.292977  0.379195  0.474230\n",
       "  2.00  0.160586  0.203147  0.264829  0.340638  0.421238  0.518098  0.612783\n",
       "  2.50  0.227700  0.283222  0.356599  0.443201  0.530683  0.626457  0.713326\n",
       "  3.00  0.290796  0.357652  0.438825  0.528099  0.612890  0.702986  0.778356,\n",
       "  'b_tau_tau_hadronic':         1000.0    1250.0    1500.0    1750.0    2000.0    2250.0    2500.0\n",
       "  0.25  0.009723  0.013115  0.018052  0.024822  0.035192  0.050709  0.073957\n",
       "  0.50  0.037559  0.050154  0.068387  0.093384  0.127117  0.176273  0.242029\n",
       "  1.00  0.135454  0.175300  0.228337  0.291527  0.367122  0.460374  0.559930\n",
       "  1.50  0.260425  0.322000  0.397015  0.478806  0.566900  0.656826  0.741271\n",
       "  2.00  0.382766  0.455010  0.538130  0.618909  0.696881  0.771107  0.834075\n",
       "  2.50  0.488677  0.564084  0.641913  0.714470  0.781268  0.840130  0.887689\n",
       "  3.00  0.570655  0.645821  0.716650  0.778663  0.833365  0.881186  0.917728,\n",
       "  'b_tau_tau_semileptonic':         1000.0    1250.0    1500.0    1750.0    2000.0    2250.0    2500.0\n",
       "  0.25  0.010264  0.013768  0.019256  0.026644  0.038547  0.054145  0.078815\n",
       "  0.50  0.039588  0.052554  0.072700  0.099721  0.137983  0.186545  0.254891\n",
       "  1.00  0.141989  0.182539  0.240137  0.306762  0.389352  0.477603  0.576829\n",
       "  1.50  0.271098  0.332851  0.412868  0.496962  0.589951  0.672248  0.754263\n",
       "  2.00  0.395770  0.467254  0.554437  0.635896  0.716474  0.783089  0.843391\n",
       "  2.50  0.502352  0.576161  0.656892  0.729062  0.796995  0.849205  0.894376\n",
       "  3.00  0.584004  0.657010  0.729818  0.790934  0.846084  0.888241  0.922782}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c491def-6733-44e9-8ff1-41759363cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tablas_XS = {}\n",
    "for betard in betards:\n",
    "    betard_name = betard.replace('33', '')\n",
    "    Tablas_XS[betard_name] = {}\n",
    "    for data in datas:\n",
    "        for signal in signals:\n",
    "            ruta = signal.replace('LQ_LQ','dLQ').replace('Tau_LQ', 'sLQ')\n",
    "            Tablas_XS[betard_name][ruta] = pd.read_excel(f'{Path_Tablas_XS}/{betard}/{data}_{signal}.xlsx', index_col = 0)\n",
    "            Tablas_XS[betard_name][ruta].columns = [float(colum) for colum in Tablas_XS[betard_name][ruta].columns]\n",
    "            Tablas_XS[betard_name][ruta].index = [float(fila) for fila in Tablas_XS[betard_name][ruta].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db5136e-343a-4447-9995-e1a94b3e7f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Betard_minus1': {'dLQ':       250.0   500.0   750.0   1000.0   1250.0    1500.0    1750.0    2000.0  \\\n",
       "  0.25   934.1   19.89   1.523  0.1972  0.03312  0.006546  0.001417  0.000329   \n",
       "  0.50   930.1   19.96   1.523  0.1974  0.03321  0.006507  0.001409  0.000327   \n",
       "  1.00   930.6   19.97   1.531  0.1976  0.03330  0.006500  0.001417  0.000330   \n",
       "  1.50   934.1   19.95   1.533  0.1973  0.03319  0.006544  0.001423  0.000330   \n",
       "  2.00   947.1   20.28   1.548  0.2015  0.03384  0.006642  0.001442  0.000335   \n",
       "  2.50   967.5   20.95   1.616  0.2085  0.03485  0.006838  0.001479  0.000344   \n",
       "  3.00  1023.0   22.21   1.721  0.2215  0.03692  0.007156  0.001554  0.000357   \n",
       "  \n",
       "          2250.0    2500.0  \n",
       "  0.25  0.000080  0.000020  \n",
       "  0.50  0.000080  0.000020  \n",
       "  1.00  0.000079  0.000020  \n",
       "  1.50  0.000080  0.000020  \n",
       "  2.00  0.000081  0.000020  \n",
       "  2.50  0.000082  0.000020  \n",
       "  3.00  0.000085  0.000021  ,\n",
       "  'sLQ':        250.0    500.0    750.0     1000.0    1250.0    1500.0    1750.0  \\\n",
       "  0.25    3.522   0.1148  0.01177  0.001979  0.000443  0.000118  0.000035   \n",
       "  0.50   14.090   0.4571  0.04684  0.007925  0.001772  0.000470  0.000142   \n",
       "  1.00   56.150   1.8380  0.18820  0.031540  0.007076  0.001882  0.000567   \n",
       "  1.50  126.300   4.1280  0.42260  0.071310  0.015920  0.004234  0.001274   \n",
       "  2.00  224.900   7.3620  0.75220  0.126800  0.028170  0.007525  0.002269   \n",
       "  2.50  350.600  11.4600  1.17400  0.197600  0.044130  0.011790  0.003558   \n",
       "  3.00  505.000  16.4100  1.68400  0.285400  0.063480  0.016860  0.005090   \n",
       "  \n",
       "          2000.0    2250.0    2500.0  \n",
       "  0.25  0.000012  0.000004  0.000001  \n",
       "  0.50  0.000046  0.000016  0.000006  \n",
       "  1.00  0.000186  0.000065  0.000024  \n",
       "  1.50  0.000420  0.000147  0.000054  \n",
       "  2.00  0.000740  0.000261  0.000096  \n",
       "  2.50  0.001163  0.000409  0.000150  \n",
       "  3.00  0.001673  0.000589  0.000217  },\n",
       " 'Betard_0': {'dLQ':       250.0   500.0   750.0   1000.0   1250.0    1500.0    1750.0    2000.0  \\\n",
       "  0.25   931.5   19.90   1.526  0.1967  0.03335  0.006535  0.001423  0.000328   \n",
       "  0.50   933.2   19.94   1.525  0.1977  0.03335  0.006554  0.001410  0.000329   \n",
       "  1.00   930.8   19.99   1.525  0.1967  0.03323  0.006514  0.001409  0.000330   \n",
       "  1.50   930.6   19.94   1.529  0.1971  0.03349  0.006551  0.001419  0.000330   \n",
       "  2.00   938.3   20.11   1.536  0.1991  0.03375  0.006567  0.001428  0.000332   \n",
       "  2.50   954.4   20.41   1.570  0.2023  0.03411  0.006655  0.001450  0.000335   \n",
       "  3.00   977.4   21.15   1.618  0.2094  0.03497  0.006849  0.001485  0.000345   \n",
       "  \n",
       "          2250.0   2500.0  \n",
       "  0.25  0.000079  0.00002  \n",
       "  0.50  0.000080  0.00002  \n",
       "  1.00  0.000080  0.00002  \n",
       "  1.50  0.000079  0.00002  \n",
       "  2.00  0.000080  0.00002  \n",
       "  2.50  0.000081  0.00002  \n",
       "  3.00  0.000082  0.00002  ,\n",
       "  'sLQ':        250.0    500.0     750.0     1000.0    1250.0    1500.0    1750.0  \\\n",
       "  0.25    1.756  0.05741  0.005891  0.000989  0.000221  0.000059  0.000018   \n",
       "  0.50    7.048  0.22840  0.023420  0.003953  0.000879  0.000236  0.000071   \n",
       "  1.00   28.200  0.92130  0.094430  0.015790  0.003527  0.000945  0.000283   \n",
       "  1.50   63.280  2.06500  0.210900  0.035560  0.007942  0.002114  0.000636   \n",
       "  2.00  112.400  3.66600  0.376700  0.063260  0.014070  0.003750  0.001132   \n",
       "  2.50  174.400  5.72500  0.588700  0.099060  0.022040  0.005847  0.001771   \n",
       "  3.00  253.200  8.24300  0.841700  0.142600  0.031840  0.008490  0.002550   \n",
       "  \n",
       "          2000.0    2250.0        2500.0  \n",
       "  0.25  0.000006  0.000002  7.527000e-07  \n",
       "  0.50  0.000023  0.000008  3.011000e-06  \n",
       "  1.00  0.000093  0.000033  1.201000e-05  \n",
       "  1.50  0.000210  0.000073  2.703000e-05  \n",
       "  2.00  0.000371  0.000130  4.783000e-05  \n",
       "  2.50  0.000583  0.000204  7.528000e-05  \n",
       "  3.00  0.000838  0.000293  1.082000e-04  }}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tablas_XS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a83a8b2-15a7-44e7-8393-b7fa38aae887",
   "metadata": {},
   "outputs": [],
   "source": [
    "significances_files = ['all_combined', 'dLQ_combined', 'dLQ_hadronic', 'dLQ_semileptonic', 'sLQ_combined', 'sLQ_hadronic', 'sLQ_semileptonic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b9060a-b4dd-4fc7-9f06-48a81d152ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Significances = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c57c471-2657-4213-b1bb-e3c36e96535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Significances['Betard_minus1'] = {}\n",
    "\n",
    "for file in significances_files:\n",
    "    \n",
    "    ruta = f'{Path_significances}/Excel_Files/Betard_minus1/{file}'\n",
    "    Significances['Betard_minus1'][file] = pd.read_excel(f'{ruta}.xlsx', index_col = 0)\n",
    "    Significances['Betard_minus1'][file].columns = [float(colum) for colum in Significances['Betard_minus1'][file].columns]\n",
    "    Significances['Betard_minus1'][file].index = [float(fila) for fila in Significances['Betard_minus1'][file].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c81857-06c1-4aab-9997-7a8b8db113e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Betard_minus1': {'all_combined':       1000.0  1250.0  1500.0  1750.0  2000.0  2250.0  2500.0\n",
       "  0.25   113.9   35.57    7.65    1.93   0.450  0.0988  0.0340\n",
       "  0.50   113.9   36.01    7.79    1.98   0.454  0.1014  0.0353\n",
       "  1.00   113.9   37.40    8.02    2.03   0.529  0.1415  0.0517\n",
       "  1.50   113.9   40.10    9.23    2.62   0.779  0.2506  0.0945\n",
       "  1.80   125.9   42.19   10.36    3.10   1.020  0.3500  0.1310\n",
       "  2.00   113.9   43.75   11.82    3.85   1.240  0.4420  0.1800\n",
       "  2.50   113.9   46.24   13.75    5.35   1.970  0.6510  0.2700\n",
       "  3.00   113.9   56.92   19.53    7.25   2.725  0.9250  0.3630,\n",
       "  'dLQ_combined':        1000.0  1250.0  1500.0  1750.0  2000.0  2250.0  2500.0\n",
       "  0.25  114.324  35.625   7.643   1.912   0.418   0.090   0.033\n",
       "  0.50  114.382  35.673   7.620   1.907   0.417   0.090   0.033\n",
       "  1.00  114.440  35.721   7.616   1.912   0.419   0.090   0.033\n",
       "  1.50  114.353  35.662   7.642   1.916   0.419   0.090   0.033\n",
       "  1.80  113.880  35.570   7.640   1.920   0.420   0.090   0.033\n",
       "  2.00  115.564  36.010   7.699   1.929   0.422   0.090   0.033\n",
       "  2.50  117.554  36.543   7.812   1.954   0.427   0.091   0.033\n",
       "  3.00  121.164  37.613   7.991   2.003   0.436   0.093   0.034,\n",
       "  'dLQ_hadronic':       1000.0  1250.0  1500.0  1750.0  2000.0  2250.0  2500.0\n",
       "  0.25  87.912  30.647   6.402   1.345   0.359   0.084   0.027\n",
       "  0.50  87.956  30.689   6.383   1.341   0.358   0.084   0.027\n",
       "  1.00  88.001  30.730   6.380   1.345   0.359   0.084   0.027\n",
       "  1.50  87.934  30.679   6.401   1.347   0.359   0.084   0.027\n",
       "  1.80  87.570  30.600   6.400   1.350   0.360   0.084   0.027\n",
       "  2.00  88.865  30.978   6.449   1.356   0.362   0.084   0.027\n",
       "  2.50  90.395  31.437   6.544   1.374   0.366   0.085   0.027\n",
       "  3.00  96.220  34.210   6.610   1.460   0.390   0.089   0.028,\n",
       "  'dLQ_semileptonic':       1000.0  1250.0  1500.0  1750.0  2000.0  2250.0  2500.0\n",
       "  0.25  74.811  19.230   4.382   1.374   0.239   0.039   0.018\n",
       "  0.50  74.849  19.256   4.369   1.371   0.238   0.039   0.018\n",
       "  1.00  74.887  19.282   4.366   1.374   0.239   0.039   0.018\n",
       "  1.50  74.830  19.250   4.381   1.377   0.239   0.039   0.018\n",
       "  1.80  74.520  19.200   4.380   1.380   0.240   0.039   0.018\n",
       "  2.00  75.622  19.437   4.414   1.387   0.241   0.039   0.018\n",
       "  2.50  76.924  19.725   4.478   1.404   0.244   0.039   0.018\n",
       "  3.00  79.286  20.303   4.581   1.439   0.249   0.040   0.018,\n",
       "  'sLQ_combined':         1000.0  1250.0   1500.0   1750.0  2000.0  2250.0  2500.0\n",
       "  0.25    1.2402   0.383   0.1272  0.04686  0.0183  0.0063  0.0024\n",
       "  0.50    4.8010   1.503   0.5050  0.18420  0.0702  0.0260  0.0099\n",
       "  1.00   17.2000   5.712   1.9700  0.72880  0.2800  0.1010  0.0390\n",
       "  1.50   38.4000  12.010   4.2700  1.60700  0.6300  0.2300  0.0855\n",
       "  1.80   61.5700  19.350   6.5300  2.38000  0.9000  0.3300  0.1200\n",
       "  2.00   74.9600  23.660   8.0330  2.94000  1.1170  0.4250  0.1600\n",
       "  2.50  113.0100  36.490  12.7900  4.60000  1.7900  0.6350  0.2500\n",
       "  3.00  157.4000  51.560  17.7040  6.55000  2.5230  0.9133  0.3577,\n",
       "  'sLQ_hadronic':        1000.0  1250.0  1500.0  1750.0  2000.0  2250.0  2500.0\n",
       "  0.25    0.976   0.314   0.111   0.043   0.016   0.005   0.002\n",
       "  0.50    3.751   1.228   0.440   0.166   0.065   0.022   0.009\n",
       "  1.00   13.159   4.607   1.709   0.656   0.252   0.086   0.036\n",
       "  1.50   25.850   9.545   3.680   1.442   0.564   0.193   0.079\n",
       "  1.80   47.970  15.780   5.690   2.150   0.810   0.280   0.114\n",
       "  2.00   58.250  19.270   6.993   2.650   1.010   0.354   0.145\n",
       "  2.50   87.238  29.600  11.190   4.140   1.610   0.554   0.225\n",
       "  3.00  120.690  41.650  15.370   5.890   2.270   0.778   0.325,\n",
       "  'sLQ_semileptonic':       1000.0   1250.0  1500.0  1750.0  2000.0  2250.0   2500.0\n",
       "  0.25   0.703   0.2067  0.0600  0.0198  0.0088  0.0032  0.00098\n",
       "  0.50   2.741   0.8174  0.2400  0.0740  0.0320  0.0140  0.00370\n",
       "  1.00   9.906   3.1620  0.9497  0.2935  0.1133  0.0500  0.01670\n",
       "  1.50  19.980   6.7620  2.1010  0.6561  0.2554  0.1130  0.03360\n",
       "  1.80  35.217  10.5400  3.1000  0.9500  0.3700  0.1600  0.04400\n",
       "  2.00  42.940  12.9200  3.8300  1.1760  0.4510  0.2190  0.06700\n",
       "  2.50  64.920  20.0300  5.9800  1.8420  0.7220  0.3300  0.10400\n",
       "  3.00  90.620  28.4800  8.5200  2.6340  1.0210  0.4520  0.15100}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Significances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae942bb8-3524-4afc-9675-bc3065936ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Masses = ['1000', '1250', '1500', '1750', '2000', '2250', '2500']\n",
    "g_Us = ['0.25', '0.5', '1', '1.5', '2.0', '2.5', '3.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f0720-8915-46cf-94db-3ed5ff3c85ac",
   "metadata": {},
   "source": [
    "Ahora usemos esto para construir las tablas de significancia con betard0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9411ece-09d9-4e35-8ada-3acd2cef0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Significances['Betard_0'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3ef4014-c466-4325-96ff-ea6befe94b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sLQ'\n",
    "channel = 'hadronic'\n",
    "process = 'b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0'][f'{file_name}'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1'][f'{file_name}'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC = Compositions['Betard_0'][f'{process}_{channel}'][M][g_U]\n",
    "        Composition_w_RHC = Compositions['Betard_minus1'][f'{process}_{channel}'][M][g_U]\n",
    "        \n",
    "        factor = np.sqrt((Eficiencia_M_wo_RHC/Eficiencia_M_w_RHC)*(XS_wo_RHC/XS_w_RHC)*(Composition_w_RHC/Composition_wo_RHC))        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f3cd976-2d87-4f29-9c0b-82726d8e1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sLQ'\n",
    "channel = 'semileptonic'\n",
    "process = 'b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0'][f'{file_name}'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1'][f'{file_name}'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC = Compositions['Betard_0'][f'{process}_{channel}'][M][g_U]\n",
    "        Composition_w_RHC = Compositions['Betard_minus1'][f'{process}_{channel}'][M][g_U]\n",
    "        \n",
    "        factor = np.sqrt((Eficiencia_M_wo_RHC/Eficiencia_M_w_RHC)*(XS_wo_RHC/XS_w_RHC)*(Composition_w_RHC/Composition_wo_RHC))        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7366fc18-f728-47f0-9f0b-4f55ee2de774",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dLQ'\n",
    "channel = 'hadronic'\n",
    "process = 'b_b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0']['sLQ'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1']['sLQ'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC = Compositions['Betard_0'][f'{process}_{channel}'][M][g_U]\n",
    "        Composition_w_RHC = Compositions['Betard_minus1'][f'{process}_{channel}'][M][g_U]\n",
    "        \n",
    "        factor = np.sqrt((Eficiencia_M_wo_RHC/Eficiencia_M_w_RHC)*(XS_wo_RHC/XS_w_RHC)*(Composition_w_RHC/Composition_wo_RHC))        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2989a765-f2e6-4165-addd-7cd75ab9048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dLQ'\n",
    "channel = 'semileptonic'\n",
    "process = 'b_b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC = Eficiencia(process, channel, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0']['sLQ'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1']['sLQ'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC = Compositions['Betard_0'][f'{process}_{channel}'][M][g_U]\n",
    "        Composition_w_RHC = Compositions['Betard_minus1'][f'{process}_{channel}'][M][g_U]\n",
    "        \n",
    "        factor = np.sqrt((Eficiencia_M_wo_RHC/Eficiencia_M_w_RHC)*(XS_wo_RHC/XS_w_RHC)*(Composition_w_RHC/Composition_wo_RHC))        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21a34f4-cf35-4f5c-addd-d29428d9211a",
   "metadata": {},
   "source": [
    "Solo falta las Combinadas de cada una y All Combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ead6e15-a8d5-4ddc-9530-b5109cfc4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sLQ'\n",
    "channel = 'combined'\n",
    "\n",
    "channel_1 = 'hadronic'\n",
    "channel_2 = 'semileptonic'\n",
    "\n",
    "process = 'b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC_1 = Eficiencia(process, channel_1, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_1 = Eficiencia(process, channel_1, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        Eficiencia_M_wo_RHC_2 = Eficiencia(process, channel_2, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_2 = Eficiencia(process, channel_2, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        Composition_wo_RHC_1 = Compositions['Betard_0'][f'{process}_{channel_1}'][M][g_U]\n",
    "        Composition_w_RHC_1 = Compositions['Betard_minus1'][f'{process}_{channel_1}'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC_2 = Compositions['Betard_0'][f'{process}_{channel_2}'][M][g_U]\n",
    "        Composition_w_RHC_2 = Compositions['Betard_minus1'][f'{process}_{channel_2}'][M][g_U]\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0'][f'{file_name}'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1'][f'{file_name}'][M][g_U]\n",
    "        \n",
    "        numerador = (Eficiencia_M_wo_RHC_1/Composition_wo_RHC_1 + Eficiencia_M_wo_RHC_2/Composition_wo_RHC_2)*XS_wo_RHC\n",
    "        denominador = (Eficiencia_M_w_RHC_1/Composition_w_RHC_1 + Eficiencia_M_w_RHC_2/Composition_w_RHC_2)*XS_w_RHC\n",
    "        \n",
    "        factor = np.sqrt(numerador/denominador)        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "809abc5a-b358-4a59-acb2-870d76075c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dLQ'\n",
    "channel = 'combined'\n",
    "\n",
    "channel_1 = 'hadronic'\n",
    "channel_2 = 'semileptonic'\n",
    "\n",
    "process = 'b_b_tau_tau' \n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "\n",
    "        Eficiencia_M_wo_RHC_1 = Eficiencia(process, channel_1, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_1 = Eficiencia(process, channel_1, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        Eficiencia_M_wo_RHC_2 = Eficiencia(process, channel_2, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_2 = Eficiencia(process, channel_2, f'Tau_LQ_{Masses[j]}')\n",
    "        \n",
    "        Composition_wo_RHC_1 = Compositions['Betard_0'][f'{process}_{channel_1}'][M][g_U]\n",
    "        Composition_w_RHC_1 = Compositions['Betard_minus1'][f'{process}_{channel_1}'][M][g_U]\n",
    "        \n",
    "        Composition_wo_RHC_2 = Compositions['Betard_0'][f'{process}_{channel_2}'][M][g_U]\n",
    "        Composition_w_RHC_2 = Compositions['Betard_minus1'][f'{process}_{channel_2}'][M][g_U]\n",
    "        \n",
    "        XS_wo_RHC = Tablas_XS['Betard_0']['sLQ'][M][g_U]\n",
    "        XS_w_RHC = Tablas_XS['Betard_minus1']['sLQ'][M][g_U]\n",
    "        \n",
    "        numerador = (Eficiencia_M_wo_RHC_1/Composition_wo_RHC_1 + Eficiencia_M_wo_RHC_2/Composition_wo_RHC_2)*XS_wo_RHC\n",
    "        denominador = (Eficiencia_M_w_RHC_1/Composition_w_RHC_1 + Eficiencia_M_w_RHC_2/Composition_w_RHC_2)*XS_w_RHC\n",
    "        \n",
    "        factor = np.sqrt(numerador/denominador)        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beea586d-950f-47a5-9233-0e97b377951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'all'\n",
    "channel = 'combined'\n",
    "\n",
    "channel_1 = 'hadronic'\n",
    "channel_2 = 'semileptonic'\n",
    "\n",
    "process_1 = 'b_tau_tau' #sLQ\n",
    "process_2 = 'b_b_tau_tau' #dLQ\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = np.zeros([len(g_Us), len(Masses)])\n",
    "\n",
    "for i in range(len(g_Us)):\n",
    "    for j in range(len(Masses)):\n",
    "        g_U = float(g_Us[i])\n",
    "        M = float(Masses[j])\n",
    "        \n",
    "        #sLQ_hadronic\n",
    "        Eficiencia_M_wo_RHC_1 = Eficiencia(process_1, channel_1, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_1 = Eficiencia(process_1, channel_1, f'Tau_LQ_{Masses[j]}')\n",
    "        Composition_wo_RHC_1 = Compositions['Betard_0'][f'{process_1}_{channel_1}'][M][g_U]\n",
    "        Composition_w_RHC_1 = Compositions['Betard_minus1'][f'{process_1}_{channel_1}'][M][g_U]\n",
    "        \n",
    "        #sLQ_semiletpnic\n",
    "        Eficiencia_M_wo_RHC_2 = Eficiencia(process_1, channel_2, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_2 = Eficiencia(process_1, channel_2, f'Tau_LQ_{Masses[j]}')\n",
    "        Composition_wo_RHC_2 = Compositions['Betard_0'][f'{process_1}_{channel_2}'][M][g_U]\n",
    "        Composition_w_RHC_2 = Compositions['Betard_minus1'][f'{process_1}_{channel_2}'][M][g_U]\n",
    "        \n",
    "        #dLQ_hadronic\n",
    "        Eficiencia_M_wo_RHC_3 = Eficiencia(process_2, channel_1, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_3 = Eficiencia(process_2, channel_1, f'Tau_LQ_{Masses[j]}')\n",
    "        Composition_wo_RHC_3 = Compositions['Betard_0'][f'{process_2}_{channel_1}'][M][g_U]\n",
    "        Composition_w_RHC_3 = Compositions['Betard_minus1'][f'{process_2}_{channel_1}'][M][g_U]\n",
    "        \n",
    "        #dLQ_semiletpnic\n",
    "        Eficiencia_M_wo_RHC_4 = Eficiencia(process_2, channel_2, f'Tau_LQ_{Masses[j]}_wo_RHC')\n",
    "        Eficiencia_M_w_RHC_4 = Eficiencia(process_2, channel_2, f'Tau_LQ_{Masses[j]}')\n",
    "        Composition_wo_RHC_4 = Compositions['Betard_0'][f'{process_2}_{channel_2}'][M][g_U]\n",
    "        Composition_w_RHC_4 = Compositions['Betard_minus1'][f'{process_2}_{channel_2}'][M][g_U]\n",
    "        \n",
    "        \n",
    "        XS_wo_RHC_sLQ = Tablas_XS['Betard_0']['sLQ'][M][g_U]\n",
    "        XS_w_RHC_sLQ = Tablas_XS['Betard_minus1']['sLQ'][M][g_U]    \n",
    "        \n",
    "        numerador = (Eficiencia_M_wo_RHC_1/Composition_wo_RHC_1 + Eficiencia_M_wo_RHC_2/Composition_wo_RHC_2)*XS_wo_RHC_sLQ\n",
    "        + (Eficiencia_M_wo_RHC_3/Composition_wo_RHC_3 + Eficiencia_M_wo_RHC_4/Composition_wo_RHC_4)*XS_wo_RHC_sLQ\n",
    "        \n",
    "        denominador = (Eficiencia_M_w_RHC_1/Composition_w_RHC_1 + Eficiencia_M_w_RHC_2/Composition_w_RHC_2)*XS_w_RHC_sLQ\n",
    "        + (Eficiencia_M_w_RHC_3/Composition_w_RHC_3 + Eficiencia_M_w_RHC_4/Composition_w_RHC_4)*XS_w_RHC_sLQ\n",
    "        \n",
    "        factor = np.sqrt(numerador/denominador)        \n",
    "        \n",
    "        Significances['Betard_0'][f'{file_name}_{channel}'][i,j] = Significances['Betard_minus1'][f'{file_name}_{channel}'][M][g_U]*factor\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'] = pd.DataFrame(Significances['Betard_0'][f'{file_name}_{channel}'])\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].columns = [float(M) for M in Masses]\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].index = [float(fila) for fila in g_Us]\n",
    "\n",
    "Significances['Betard_0'][f'{file_name}_{channel}'].to_excel(f'{Path_significances}/Excel_Files/Betard_0/{file_name}_{channel}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14bfed-faf9-4f03-bd97-e29b024d1968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
